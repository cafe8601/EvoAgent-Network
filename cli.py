#!/usr/bin/env python3
"""
HAES CLI - Hybrid AI Evolution System ëŒ€í™”í˜• ì¸í„°í˜ì´ìŠ¤

í„°ë¯¸ë„ì—ì„œ HAESì™€ ëŒ€í™”í•  ìˆ˜ ìˆëŠ” CLI
"""

import asyncio
import os
import sys
from pathlib import Path

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
from dotenv import load_dotenv
load_dotenv()

from rich.console import Console
from rich.panel import Panel
from rich.markdown import Markdown
from rich.table import Table
from rich.prompt import Prompt, IntPrompt
from rich import print as rprint

from haes import HybridAISystem, Config
from haes.llm import OpenAIClient


console = Console()


def print_banner():
    """ì‹œì‘ ë°°ë„ˆ ì¶œë ¥"""
    banner = """
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                               â•‘
â•‘   ğŸš€ HAES - Hybrid AI Evolution System                       â•‘
â•‘                                                               â•‘
â•‘   63ê°œ AI Research SKILLs + 159ê°œ ì „ë¬¸ ì—ì´ì „íŠ¸              â•‘
â•‘   GPT-5.1 ê¸°ë°˜ í•˜ì´ë¸Œë¦¬ë“œ AI ì‹œìŠ¤í…œ                          â•‘
â•‘                                                               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""
    console.print(banner, style="bold cyan")


def print_help():
    """ë„ì›€ë§ ì¶œë ¥"""
    help_table = Table(title="ğŸ“š ëª…ë ¹ì–´ ë„ì›€ë§", show_header=True)
    help_table.add_column("ëª…ë ¹ì–´", style="cyan")
    help_table.add_column("ì„¤ëª…", style="white")
    
    help_table.add_row("/help", "ë„ì›€ë§ í‘œì‹œ")
    help_table.add_row("/stats", "ì‹œìŠ¤í…œ í†µê³„ í‘œì‹œ")
    help_table.add_row("/skills", "SKILL ëª©ë¡ í‘œì‹œ")
    help_table.add_row("/history", "ëŒ€í™” íˆìŠ¤í† ë¦¬")
    help_table.add_row("/clear", "íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”")
    help_table.add_row("/feedback <1-5>", "ë§ˆì§€ë§‰ ì‘ë‹µ í‰ê°€")
    help_table.add_row("/quit", "ì¢…ë£Œ")
    
    console.print(help_table)


def print_stats(system: HybridAISystem):
    """ì‹œìŠ¤í…œ í†µê³„ ì¶œë ¥"""
    stats = system.get_stats()
    
    table = Table(title="ğŸ“Š ì‹œìŠ¤í…œ í†µê³„", show_header=True)
    table.add_column("í•­ëª©", style="cyan")
    table.add_column("ê°’", style="green")
    
    table.add_row("ì¸ë±ì‹±ëœ SKILL", str(stats["skill_store"]["total_skills"]))
    table.add_row("ë¡œë“œëœ ì—ì´ì „íŠ¸", str(stats["agent_pool"]["total_agents"]))
    table.add_row("í”¼ë“œë°± ìˆ˜", str(stats["feedback"]["total"]))
    table.add_row("í•™ìŠµëœ íŒ¨í„´", str(stats["evolution"]["learned_patterns_count"]))
    table.add_row("ëŒ€í™” ìˆ˜", str(stats["history_length"] // 2))
    
    if stats["evolution"]["total_feedbacks"] > 0:
        table.add_row("í‰ê·  í‰ì ", f"{stats['evolution']['average_score']:.2f}")
    
    console.print(table)


def print_skills(system: HybridAISystem):
    """SKILL ëª©ë¡ ì¶œë ¥"""
    index = system.get_compressed_index()
    console.print(Panel(index, title="ğŸ“š SKILL ì¸ë±ìŠ¤", border_style="blue"))


def print_history(system: HybridAISystem):
    """ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¶œë ¥"""
    if not system.history:
        console.print("[yellow]ëŒ€í™” íˆìŠ¤í† ë¦¬ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.[/yellow]")
        return
    
    for i, entry in enumerate(system.history):
        role = entry["role"]
        content = entry["content"][:100] + "..." if len(entry["content"]) > 100 else entry["content"]
        
        if role == "user":
            console.print(f"[cyan]ğŸ‘¤ ì‚¬ìš©ì:[/cyan] {content}")
        else:
            mode = entry.get("metadata", {}).get("mode", "unknown")
            console.print(f"[green]ğŸ¤– AI ({mode}):[/green] {content}")


async def main():
    """ë©”ì¸ CLI í•¨ìˆ˜"""
    print_banner()
    
    # 1. OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    console.print("\n[yellow]â³ OpenAI ì—°ê²° ì¤‘...[/yellow]")
    try:
        llm_client = OpenAIClient(
            routing_model=os.getenv("ROUTING_MODEL", "gpt-5-mini"),
            main_model=os.getenv("MAIN_MODEL", "gpt-5.1"),
        )
        console.print(f"[green]âœ… ì—°ê²° ì„±ê³µ![/green] (ëª¨ë¸: {llm_client.main_model})")
    except Exception as e:
        console.print(f"[red]âŒ OpenAI ì—°ê²° ì‹¤íŒ¨: {e}[/red]")
        console.print("[yellow]Mock ëª¨ë“œë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.[/yellow]")
        llm_client = None
    
    # 2. ì‹œìŠ¤í…œ ì„¤ì •
    # ì‹¤ì œ SKILL/Agent ê²½ë¡œ ì‚¬ìš©
    project_root = Path("/home/cafe99/anti-gravity-project")
    skills_path = project_root / "AI-research-SKILLs"
    agents_path = project_root / ".claude" / "agents"
    
    if not skills_path.exists():
        # ìƒ˜í”Œ ë°ì´í„° ì‚¬ìš©
        console.print("[yellow]âš ï¸ ì‹¤ì œ SKILL ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ìƒ˜í”Œ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.[/yellow]")
        skills_path = Path(__file__).parent / "tests" / "fixtures" / "sample_skills"
        agents_path = Path(__file__).parent / "tests" / "fixtures" / "sample_agents"
    
    config = Config(
        skills_path=skills_path,
        agents_path=agents_path,
        persist_dir=Path(__file__).parent / "cli_vectordb",
    )
    
    # 3. ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    console.print("\n[yellow]â³ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...[/yellow]")
    system = HybridAISystem(config=config, llm_client=llm_client)
    stats = system.initialize()
    console.print(f"[green]âœ… ì´ˆê¸°í™” ì™„ë£Œ![/green] (SKILL: {stats['skills_indexed']}, ì—ì´ì „íŠ¸: {stats['agents_loaded']})")
    
    # ë„ì›€ë§ í‘œì‹œ
    console.print("\n[dim]'/help'ë¥¼ ì…ë ¥í•˜ë©´ ëª…ë ¹ì–´ ëª©ë¡ì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.[/dim]")
    console.print("[dim]ì¢…ë£Œí•˜ë ¤ë©´ '/quit'ë¥¼ ì…ë ¥í•˜ì„¸ìš”.[/dim]\n")
    
    # 4. ëŒ€í™” ë£¨í”„
    while True:
        try:
            # ì‚¬ìš©ì ì…ë ¥
            query = Prompt.ask("\n[bold cyan]ğŸ‘¤ ì§ˆë¬¸[/bold cyan]")
            
            if not query.strip():
                continue
            
            # ëª…ë ¹ì–´ ì²˜ë¦¬
            if query.startswith("/"):
                cmd = query.lower().split()[0]
                
                if cmd == "/quit" or cmd == "/exit":
                    console.print("[yellow]ğŸ‘‹ ì•ˆë…•íˆ ê°€ì„¸ìš”![/yellow]")
                    break
                
                elif cmd == "/help":
                    print_help()
                    continue
                
                elif cmd == "/stats":
                    print_stats(system)
                    continue
                
                elif cmd == "/skills":
                    print_skills(system)
                    continue
                
                elif cmd == "/history":
                    print_history(system)
                    continue
                
                elif cmd == "/clear":
                    system.history.clear()
                    console.print("[green]âœ… íˆìŠ¤í† ë¦¬ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.[/green]")
                    continue
                
                elif cmd == "/feedback":
                    parts = query.split()
                    if len(parts) < 2:
                        score = IntPrompt.ask("í‰ì  (1-5)")
                    else:
                        try:
                            score = int(parts[1])
                        except:
                            console.print("[red]ì˜¬ë°”ë¥¸ ì ìˆ˜ë¥¼ ì…ë ¥í•˜ì„¸ìš” (1-5)[/red]")
                            continue
                    
                    if 1 <= score <= 5:
                        try:
                            system.feedback(score=score)
                            console.print(f"[green]âœ… í”¼ë“œë°± ì €ì¥: {score}ì [/green]")
                        except ValueError as e:
                            console.print(f"[red]{e}[/red]")
                    else:
                        console.print("[red]ì ìˆ˜ëŠ” 1-5 ì‚¬ì´ì—¬ì•¼ í•©ë‹ˆë‹¤.[/red]")
                    continue
                
                else:
                    console.print(f"[red]ì•Œ ìˆ˜ ì—†ëŠ” ëª…ë ¹ì–´: {cmd}[/red]")
                    continue
            
            # ì¼ë°˜ ì§ˆë¬¸ ì²˜ë¦¬
            console.print("\n[yellow]â³ ì²˜ë¦¬ ì¤‘...[/yellow]")
            
            result = await system.chat(query)
            
            # ê²°ê³¼ ì¶œë ¥
            mode_icons = {
                "skill_only": "ğŸ“š",
                "skill_agent": "ğŸ¤–",
                "parallel": "âš¡",
                "multi_agent": "ğŸ‘¥",
            }
            icon = mode_icons.get(result.mode, "ğŸ’¬")
            
            # ë©”íƒ€ ì •ë³´
            meta = f"[dim]ëª¨ë“œ: {result.mode} | ì‹œê°„: {result.execution_time:.2f}s"
            if result.skills_used:
                meta += f" | SKILL: {', '.join(result.skills_used)}"
            if result.agents_used:
                meta += f" | ì—ì´ì „íŠ¸: {', '.join(result.agents_used)}"
            meta += "[/dim]"
            console.print(meta)
            
            # ì‘ë‹µ ì¶œë ¥
            console.print(Panel(
                Markdown(result.response),
                title=f"{icon} AI ì‘ë‹µ",
                border_style="green",
            ))
            
            # í”¼ë“œë°± íŒíŠ¸
            console.print("[dim]'/feedback 5' ëª…ë ¹ìœ¼ë¡œ ì‘ë‹µì„ í‰ê°€í•´ì£¼ì„¸ìš”.[/dim]")
            
        except KeyboardInterrupt:
            console.print("\n[yellow]ğŸ‘‹ ì•ˆë…•íˆ ê°€ì„¸ìš”![/yellow]")
            break
        except Exception as e:
            console.print(f"[red]ì˜¤ë¥˜ ë°œìƒ: {e}[/red]")


if __name__ == "__main__":
    asyncio.run(main())
