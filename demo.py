#!/usr/bin/env python3
"""
HAES Demo - Hybrid AI Evolution System ë°ëª¨

OpenAI GPT-5-mini/GPT-5.1 ì—°ë™ í…ŒìŠ¤íŠ¸
"""

import asyncio
import os
from pathlib import Path

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
from dotenv import load_dotenv
load_dotenv()

from haes import HybridAISystem, Config
from haes.llm import OpenAIClient


async def main():
    """ë©”ì¸ ë°ëª¨ í•¨ìˆ˜"""
    print("=" * 60)
    print("ğŸš€ HAES - Hybrid AI Evolution System Demo")
    print("=" * 60)
    
    # 1. OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    print("\n[1] OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”...")
    try:
        llm_client = OpenAIClient(
            routing_model=os.getenv("ROUTING_MODEL", "gpt-5-mini"),
            main_model=os.getenv("MAIN_MODEL", "gpt-5.1"),
        )
        print(f"   âœ… ë¼ìš°íŒ… ëª¨ë¸: {llm_client.routing_model}")
        print(f"   âœ… ë©”ì¸ ëª¨ë¸: {llm_client.main_model}")
    except Exception as e:
        print(f"   âŒ ì˜¤ë¥˜: {e}")
        print("   Mock ëª¨ë“œë¡œ ì‹¤í–‰...")
        llm_client = None
    
    # 2. ì‹œìŠ¤í…œ ì„¤ì •
    print("\n[2] ì‹œìŠ¤í…œ ì„¤ì •...")
    
    # ìƒ˜í”Œ ë°ì´í„° ê²½ë¡œ ì‚¬ìš©
    project_root = Path(__file__).parent
    config = Config(
        skills_path=project_root / "tests" / "fixtures" / "sample_skills",
        agents_path=project_root / "tests" / "fixtures" / "sample_agents",
        persist_dir=project_root / "demo_vectordb",
    )
    
    # 3. ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    print("\n[3] HybridAISystem ì´ˆê¸°í™”...")
    system = HybridAISystem(config=config, llm_client=llm_client)
    stats = system.initialize()
    print(f"   âœ… SKILL ì¸ë±ì‹±: {stats['skills_indexed']}ê°œ")
    print(f"   âœ… ì—ì´ì „íŠ¸ ë¡œë“œ: {stats['agents_loaded']}ê°œ")
    
    # 4. API ì—°ê²° í…ŒìŠ¤íŠ¸ (LLM í´ë¼ì´ì–¸íŠ¸ ìˆëŠ” ê²½ìš°)
    if llm_client:
        print("\n[4] OpenAI API ì—°ê²° í…ŒìŠ¤íŠ¸...")
        success = await llm_client.test_connection()
        if success:
            print("   âœ… API ì—°ê²° ì„±ê³µ!")
        else:
            print("   âŒ API ì—°ê²° ì‹¤íŒ¨")
    
    # 5. ìƒ˜í”Œ ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸
    print("\n[5] ìƒ˜í”Œ ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸...")
    print("-" * 50)
    
    queries = [
        "LoRAê°€ ë­ì•¼?",
        "íŒŒì¸íŠœë‹ ë°©ë²• ì•Œë ¤ì¤˜",
        "RAG ì‹œìŠ¤í…œ êµ¬í˜„í•´ì¤˜",
    ]
    
    for i, query in enumerate(queries, 1):
        print(f"\nğŸ“ ì¿¼ë¦¬ {i}: {query}")
        
        result = await system.chat(query)
        
        print(f"   ëª¨ë“œ: {result.mode}")
        print(f"   ì‚¬ìš©ëœ SKILL: {result.skills_used}")
        print(f"   ì‹¤í–‰ ì‹œê°„: {result.execution_time:.2f}s")
        print(f"   ì‘ë‹µ ë¯¸ë¦¬ë³´ê¸°: {result.response[:100]}...")
        
        # í”¼ë“œë°± (ëœë¤)
        import random
        score = random.choice([4, 5])
        system.feedback(score=score, comment="í…ŒìŠ¤íŠ¸ í”¼ë“œë°±")
        print(f"   í”¼ë“œë°±: {score}ì ")
    
    # 6. ì‹œìŠ¤í…œ í†µê³„
    print("\n[6] ì‹œìŠ¤í…œ í†µê³„")
    print("-" * 50)
    stats = system.get_stats()
    print(f"   í”¼ë“œë°± ì´ê³„: {stats['feedback']['total']}")
    print(f"   Evolution íŒ¨í„´: {stats['evolution']['learned_patterns_count']}ê°œ")
    print(f"   ëŒ€í™” íˆìŠ¤í† ë¦¬: {stats['history_length']}ê°œ")
    
    print("\n" + "=" * 60)
    print("ğŸ‰ ë°ëª¨ ì™„ë£Œ!")
    print("=" * 60)


if __name__ == "__main__":
    asyncio.run(main())
